{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **My first CNN classifier**\n",
        "## Loading data"
      ],
      "metadata": {
        "id": "R9CijJGdOsp1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rslc3WnUAIaN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader #to wraps an iterable around the dataset\n",
        "from torchvision import datasets \n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil#shell utils\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ],
      "metadata": {
        "id": "Z3IEFL_oSX70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Amount of training data: {len(training_data.targets)}, and test data: {len(test_data.targets)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4f9ONTItCxa",
        "outputId": "f271eede-c431-46b9-f7ef-bc94b7a1e0e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Amount of training data: 60000, and test data: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **DataLoader** object wraps an iterable over our dataset sopporting automatic batching. More about Datasets and DataLoaders [here](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)"
      ],
      "metadata": {
        "id": "zAkkMgBHTHOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrVXt7vASsfi",
        "outputId": "900dd767-c3c0-4fdf-cdea-42b374139ec3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data visualization"
      ],
      "metadata": {
        "id": "SKv9s0_0ctJ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_map = {\n",
        "    0: \"T-Shirt\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle Boot\",\n",
        "}\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
        "    img, label = training_data[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(labels_map[label])\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "_Wo7Z2znTjaV",
        "outputId": "5be1f2de-7009-4c9d-d6a5-1c90d4b48df5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Creating model**\n",
        "* **__init__ function**: define the network's layers\n",
        "* **forward function**: how the data will pass through net's layers"
      ],
      "metadata": {
        "id": "TyLnFYoBduBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#first set the running device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Running on: {device} device\")\n",
        "\n",
        "#Defining the model\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_relu_stack = nn.Sequential(nn.Linear(in_features=28*28, out_features=512),\n",
        "                                           nn.ReLU(),\n",
        "                                           nn.Linear(512, 512),\n",
        "                                           nn.ReLU(),\n",
        "                                           nn.Linear(512, 10))\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.linear_relu_stack(x)\n",
        "    return logits"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vrxk5zqxTk7C",
        "outputId": "01fc917e-053b-41b2-f020-cc78648dd04c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on: cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#let's have a model look\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "745p1v67gEeW",
        "outputId": "d97e9c1b-85bd-48bc-c044-3b4263e572a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "if you want to know more about pretrained models available [click here](https://pytorch.org/vision/stable/models.html)"
      ],
      "metadata": {
        "id": "QZE5Lg-Yaw9H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Optimizing model parameters**\n",
        "\n",
        "For train the network we need a loss function (all loss functions available [here](https://pytorch.org/docs/stable/nn.html#loss-functions)) and optimizer"
      ],
      "metadata": {
        "id": "_RoComy3ijLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "b6gTmlEeiaVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training loop\n",
        "def training(model, dataloader, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)#actual dataset size\n",
        "  model.train()\n",
        "  for batch_id, (X, y) in enumerate(dataloader):\n",
        "    X, y = X.to(device), y.to(device)\n",
        "    \n",
        "    #getting the class predictions\n",
        "    pred = model(X)\n",
        "    #computing the loss\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    # weights update\n",
        "    optimizer.zero_grad() # to \"clean\" the gradients memory\n",
        "    loss.backward() # chain rule \n",
        "    optimizer.step() # weights updating\n",
        "\n",
        "    if batch_id % 100 == 0:\n",
        "      loss, current_sample = loss.item(), batch_id*len(X)\n",
        "      print(f\"loss: {loss:>3f} [{current_sample:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "id": "rThH5l4ij5JC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test loop\n",
        "def test(model, dataloader, loss_fn):\n",
        "  size = len(dataloader.dataset)#amount of available data\n",
        "  num_batches = len(dataloader) \n",
        "  model.eval()#avoid the model learning\n",
        "  test_loss, correct = 0, 0\n",
        "  # no gradients calculation\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      #get the predictions\n",
        "      pred = model(X)\n",
        "      #computing the loss \n",
        "      test_loss += loss_fn(pred, y).item() #Returns the value of this tensor as a standard Python number\n",
        "      correct += (pred.argmax(1)==y).type(torch.float).sum().item()\n",
        "  \n",
        "  test_loss /= num_batches\n",
        "  correct /= size\n",
        "  acc = 100*correct\n",
        "  print(f\"Test error: \\n Acc: {(acc):>0.1f}%, avg loss: {test_loss:>8f}\\n\")"
      ],
      "metadata": {
        "id": "WKfJidVcno0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for i in range(epochs):\n",
        "  print(f\"Epoch {i+1}\\n ---------------------------\")\n",
        "  training(model, train_dataloader, loss_fn, optimizer)\n",
        "  test(model, test_dataloader, loss_fn)\n",
        "print(\"done\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZDp1lmsoMr4",
        "outputId": "0425b4bc-6d7b-4148-f740-5e28cdb03fd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            " ---------------------------\n",
            "loss: 2.300589 [    0/60000]\n",
            "loss: 2.290185 [ 6400/60000]\n",
            "loss: 2.267891 [12800/60000]\n",
            "loss: 2.270879 [19200/60000]\n",
            "loss: 2.235893 [25600/60000]\n",
            "loss: 2.216253 [32000/60000]\n",
            "loss: 2.230269 [38400/60000]\n",
            "loss: 2.184785 [44800/60000]\n",
            "loss: 2.194162 [51200/60000]\n",
            "loss: 2.159749 [57600/60000]\n",
            "Test error: \n",
            " Acc: 46.1%, avg loss: 2.146557\n",
            "\n",
            "Epoch 2\n",
            " ---------------------------\n",
            "loss: 2.155737 [    0/60000]\n",
            "loss: 2.147227 [ 6400/60000]\n",
            "loss: 2.078121 [12800/60000]\n",
            "loss: 2.103073 [19200/60000]\n",
            "loss: 2.045417 [25600/60000]\n",
            "loss: 1.986323 [32000/60000]\n",
            "loss: 2.026939 [38400/60000]\n",
            "loss: 1.930722 [44800/60000]\n",
            "loss: 1.946407 [51200/60000]\n",
            "loss: 1.877051 [57600/60000]\n",
            "Test error: \n",
            " Acc: 54.8%, avg loss: 1.863845\n",
            "\n",
            "Epoch 3\n",
            " ---------------------------\n",
            "loss: 1.898866 [    0/60000]\n",
            "loss: 1.871133 [ 6400/60000]\n",
            "loss: 1.736239 [12800/60000]\n",
            "loss: 1.787665 [19200/60000]\n",
            "loss: 1.683090 [25600/60000]\n",
            "loss: 1.633758 [32000/60000]\n",
            "loss: 1.672157 [38400/60000]\n",
            "loss: 1.560990 [44800/60000]\n",
            "loss: 1.591211 [51200/60000]\n",
            "loss: 1.495736 [57600/60000]\n",
            "Test error: \n",
            " Acc: 61.3%, avg loss: 1.503389\n",
            "\n",
            "Epoch 4\n",
            " ---------------------------\n",
            "loss: 1.569900 [    0/60000]\n",
            "loss: 1.542314 [ 6400/60000]\n",
            "loss: 1.378497 [12800/60000]\n",
            "loss: 1.460077 [19200/60000]\n",
            "loss: 1.351484 [25600/60000]\n",
            "loss: 1.342817 [32000/60000]\n",
            "loss: 1.370916 [38400/60000]\n",
            "loss: 1.287742 [44800/60000]\n",
            "loss: 1.321630 [51200/60000]\n",
            "loss: 1.229444 [57600/60000]\n",
            "Test error: \n",
            " Acc: 63.7%, avg loss: 1.249078\n",
            "\n",
            "Epoch 5\n",
            " ---------------------------\n",
            "loss: 1.322698 [    0/60000]\n",
            "loss: 1.313762 [ 6400/60000]\n",
            "loss: 1.135674 [12800/60000]\n",
            "loss: 1.247137 [19200/60000]\n",
            "loss: 1.132508 [25600/60000]\n",
            "loss: 1.150513 [32000/60000]\n",
            "loss: 1.182845 [38400/60000]\n",
            "loss: 1.115271 [44800/60000]\n",
            "loss: 1.150770 [51200/60000]\n",
            "loss: 1.069509 [57600/60000]\n",
            "Test error: \n",
            " Acc: 64.9%, avg loss: 1.086904\n",
            "\n",
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Saving our model**\n",
        "A common way to save a model is to serialize the internal state dictionary (containing the model parameters)."
      ],
      "metadata": {
        "id": "72wuuTkUt0OL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00TVtN4zhfVp",
        "outputId": "65fe5e4e-33c6-4939-a8e2-b582579be275"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('linear_relu_stack.0.weight',\n",
              "              tensor([[ 1.9483e-03, -1.4831e-02, -1.4482e-02,  ..., -3.5126e-02,\n",
              "                       -2.4499e-02,  1.9545e-02],\n",
              "                      [ 1.9239e-02,  7.3755e-03, -1.3604e-02,  ...,  2.4648e-02,\n",
              "                        1.3223e-02, -1.5867e-02],\n",
              "                      [ 3.5655e-02, -7.8210e-05, -2.8206e-03,  ..., -1.6643e-02,\n",
              "                       -8.9523e-03, -7.5431e-03],\n",
              "                      ...,\n",
              "                      [-3.2757e-02,  1.2092e-02,  2.7388e-02,  ..., -7.2903e-03,\n",
              "                        2.1290e-02, -3.0681e-02],\n",
              "                      [ 1.7431e-02,  2.3872e-02, -2.7612e-02,  ...,  1.8316e-02,\n",
              "                       -1.3312e-02, -1.2902e-02],\n",
              "                      [ 2.4006e-02, -2.5796e-03, -1.8922e-02,  ...,  2.6491e-02,\n",
              "                        6.1834e-03,  1.2472e-02]], device='cuda:0')),\n",
              "             ('linear_relu_stack.0.bias',\n",
              "              tensor([-0.0170,  0.0221,  0.0279,  0.0277,  0.0281, -0.0227,  0.0476,  0.0149,\n",
              "                      -0.0324, -0.0216, -0.0299,  0.0208,  0.0084, -0.0215, -0.0163, -0.0040,\n",
              "                       0.0335,  0.0081, -0.0137, -0.0048,  0.0208,  0.0499,  0.0209, -0.0208,\n",
              "                       0.0172,  0.0128,  0.0105,  0.0154,  0.0299,  0.0032,  0.0154, -0.0170,\n",
              "                      -0.0196, -0.0024,  0.0379,  0.0130,  0.0397,  0.0128, -0.0069, -0.0141,\n",
              "                       0.0423,  0.0269, -0.0215, -0.0131, -0.0267, -0.0159, -0.0175,  0.0378,\n",
              "                       0.0348, -0.0210,  0.0207,  0.0066,  0.0284,  0.0252, -0.0151, -0.0060,\n",
              "                       0.0430,  0.0279, -0.0051, -0.0237, -0.0215, -0.0170, -0.0267, -0.0333,\n",
              "                       0.0357, -0.0109, -0.0175,  0.0297,  0.0153,  0.0507, -0.0205, -0.0199,\n",
              "                       0.0112,  0.0159, -0.0076,  0.0171,  0.0266,  0.0092,  0.0302,  0.0009,\n",
              "                       0.0424,  0.0223, -0.0308, -0.0132,  0.0237,  0.0319, -0.0078,  0.0233,\n",
              "                       0.0189,  0.0367, -0.0294, -0.0073, -0.0034, -0.0356, -0.0214, -0.0160,\n",
              "                      -0.0044,  0.0148, -0.0284,  0.0378,  0.0294, -0.0191,  0.0234,  0.0007,\n",
              "                      -0.0244,  0.0197, -0.0221,  0.0094,  0.0019,  0.0117, -0.0144, -0.0107,\n",
              "                      -0.0107, -0.0037,  0.0290, -0.0157,  0.0340,  0.0218,  0.0138,  0.0190,\n",
              "                       0.0214, -0.0288,  0.0285, -0.0098,  0.0450,  0.0028,  0.0172,  0.0120,\n",
              "                      -0.0073, -0.0358,  0.0027, -0.0108,  0.0047, -0.0346, -0.0287, -0.0057,\n",
              "                       0.0050, -0.0264, -0.0243, -0.0223,  0.0032, -0.0079, -0.0221, -0.0037,\n",
              "                      -0.0110,  0.0511, -0.0070, -0.0202,  0.0099, -0.0093,  0.0311,  0.0024,\n",
              "                      -0.0134, -0.0265, -0.0307,  0.0513,  0.0303,  0.0359, -0.0239,  0.0132,\n",
              "                      -0.0186,  0.0028,  0.0380,  0.0062, -0.0046,  0.0038,  0.0003,  0.0413,\n",
              "                       0.0297,  0.0056, -0.0286, -0.0315,  0.0199, -0.0316, -0.0082, -0.0031,\n",
              "                      -0.0063, -0.0086,  0.0255,  0.0229,  0.0037,  0.0061,  0.0188,  0.0284,\n",
              "                       0.0178, -0.0023, -0.0088,  0.0165, -0.0151,  0.0046, -0.0347,  0.0381,\n",
              "                      -0.0305,  0.0266, -0.0220, -0.0329,  0.0416, -0.0118, -0.0323, -0.0126,\n",
              "                      -0.0108, -0.0160,  0.0367, -0.0184,  0.0251, -0.0248,  0.0188, -0.0261,\n",
              "                       0.0404, -0.0268, -0.0066,  0.0090, -0.0097, -0.0014,  0.0033,  0.0334,\n",
              "                       0.0045, -0.0030, -0.0227, -0.0092,  0.0064,  0.0049, -0.0097,  0.0049,\n",
              "                       0.0197,  0.0060,  0.0281,  0.0285, -0.0207, -0.0334,  0.0088,  0.0335,\n",
              "                      -0.0132,  0.0072,  0.0324, -0.0325,  0.0016,  0.0108,  0.0105,  0.0144,\n",
              "                       0.0061,  0.0193,  0.0275,  0.0231,  0.0160, -0.0094,  0.0397,  0.0197,\n",
              "                       0.0019,  0.0058,  0.0164, -0.0058,  0.0113, -0.0218, -0.0221, -0.0020,\n",
              "                      -0.0024,  0.0265,  0.0055, -0.0173,  0.0003,  0.0263,  0.0161, -0.0165,\n",
              "                       0.0392,  0.0278, -0.0251,  0.0333, -0.0107,  0.0134,  0.0125,  0.0004,\n",
              "                      -0.0077, -0.0026,  0.0001, -0.0044, -0.0051,  0.0101, -0.0295,  0.0051,\n",
              "                      -0.0166,  0.0213,  0.0373, -0.0037, -0.0168,  0.0306,  0.0035, -0.0287,\n",
              "                       0.0253,  0.0341, -0.0213, -0.0108, -0.0020,  0.0428,  0.0150, -0.0074,\n",
              "                       0.0417, -0.0048, -0.0361, -0.0273,  0.0083,  0.0315,  0.0320,  0.0026,\n",
              "                       0.0238,  0.0069, -0.0158,  0.0074,  0.0189, -0.0113,  0.0246,  0.0222,\n",
              "                       0.0295, -0.0160,  0.0017, -0.0358,  0.0537,  0.0041,  0.0314, -0.0094,\n",
              "                       0.0066, -0.0076,  0.0050,  0.0035,  0.0283, -0.0134,  0.0364, -0.0137,\n",
              "                       0.0348, -0.0204, -0.0138,  0.0206,  0.0032, -0.0042, -0.0191,  0.0238,\n",
              "                       0.0175,  0.0542, -0.0210, -0.0335, -0.0338, -0.0194, -0.0059, -0.0242,\n",
              "                       0.0336,  0.0386,  0.0300,  0.0013,  0.0071, -0.0249, -0.0251,  0.0121,\n",
              "                      -0.0273, -0.0061, -0.0012, -0.0093, -0.0214,  0.0118,  0.0349,  0.0182,\n",
              "                       0.0020, -0.0184, -0.0176,  0.0360,  0.0356, -0.0227,  0.0173,  0.0030,\n",
              "                       0.0282,  0.0103, -0.0078, -0.0142, -0.0076, -0.0199,  0.0191,  0.0238,\n",
              "                       0.0189, -0.0198, -0.0234,  0.0128,  0.0166,  0.0147,  0.0073, -0.0088,\n",
              "                      -0.0092,  0.0327,  0.0212, -0.0161, -0.0291,  0.0131, -0.0123,  0.0181,\n",
              "                       0.0357,  0.0015,  0.0319, -0.0024, -0.0179, -0.0127, -0.0124, -0.0338,\n",
              "                       0.0053, -0.0134, -0.0195,  0.0163, -0.0326,  0.0313,  0.0087, -0.0276,\n",
              "                      -0.0160, -0.0143,  0.0026, -0.0332,  0.0088,  0.0143,  0.0315,  0.0233,\n",
              "                      -0.0061, -0.0163,  0.0247,  0.0395,  0.0128,  0.0098,  0.0379,  0.0048,\n",
              "                       0.0030,  0.0211, -0.0318,  0.0237, -0.0245, -0.0004,  0.0387, -0.0373,\n",
              "                       0.0068,  0.0057,  0.0162, -0.0203, -0.0008,  0.0391,  0.0087, -0.0216,\n",
              "                      -0.0319,  0.0131, -0.0256, -0.0142,  0.0316, -0.0129,  0.0450, -0.0144,\n",
              "                      -0.0069,  0.0349,  0.0174,  0.0004,  0.0277,  0.0175,  0.0146,  0.0330,\n",
              "                      -0.0071,  0.0288,  0.0233, -0.0249,  0.0011,  0.0022,  0.0053,  0.0149,\n",
              "                       0.0305,  0.0140, -0.0151,  0.0256,  0.0149, -0.0330, -0.0071, -0.0069,\n",
              "                       0.0266,  0.0188,  0.0044,  0.0072,  0.0131, -0.0061,  0.0179,  0.0225,\n",
              "                       0.0093, -0.0099,  0.0006,  0.0257,  0.0140, -0.0264, -0.0294,  0.0185,\n",
              "                      -0.0259, -0.0196, -0.0074, -0.0176,  0.0215,  0.0125, -0.0098,  0.0185,\n",
              "                       0.0344,  0.0108, -0.0037,  0.0049, -0.0043, -0.0162, -0.0020, -0.0196,\n",
              "                      -0.0102, -0.0231, -0.0049, -0.0018, -0.0141,  0.0163, -0.0372,  0.0320],\n",
              "                     device='cuda:0')),\n",
              "             ('linear_relu_stack.2.weight',\n",
              "              tensor([[ 0.0240,  0.0042,  0.0107,  ..., -0.0395, -0.0071,  0.0318],\n",
              "                      [ 0.0001, -0.0241, -0.0423,  ...,  0.0342, -0.0146,  0.0424],\n",
              "                      [ 0.0327,  0.0294,  0.0425,  ..., -0.0215, -0.0285, -0.0247],\n",
              "                      ...,\n",
              "                      [-0.0180, -0.0280, -0.0355,  ..., -0.0154, -0.0275,  0.0106],\n",
              "                      [-0.0228, -0.0118, -0.0297,  ...,  0.0045, -0.0334,  0.0360],\n",
              "                      [-0.0148, -0.0284, -0.0335,  ..., -0.0270, -0.0379, -0.0202]],\n",
              "                     device='cuda:0')),\n",
              "             ('linear_relu_stack.2.bias',\n",
              "              tensor([-0.0283,  0.0018,  0.0324, -0.0371, -0.0110,  0.0469,  0.0310,  0.0104,\n",
              "                       0.0156,  0.0136,  0.0373, -0.0124,  0.0423,  0.0320, -0.0129, -0.0002,\n",
              "                      -0.0024, -0.0002,  0.0401, -0.0283, -0.0172,  0.0037, -0.0049, -0.0154,\n",
              "                       0.0058,  0.0048, -0.0426, -0.0431,  0.0168,  0.0620,  0.0299, -0.0229,\n",
              "                       0.0143, -0.0219,  0.0263, -0.0020, -0.0015, -0.0184,  0.0462,  0.0203,\n",
              "                      -0.0085,  0.0482, -0.0406, -0.0292,  0.0093, -0.0590,  0.0231, -0.0193,\n",
              "                      -0.0204, -0.0182, -0.0171, -0.0184,  0.0031,  0.0313, -0.0151,  0.0515,\n",
              "                      -0.0375, -0.0170, -0.0270,  0.0121, -0.0130, -0.0013,  0.0292, -0.0168,\n",
              "                      -0.0076, -0.0257, -0.0382, -0.0165,  0.0444,  0.0216,  0.0339, -0.0036,\n",
              "                      -0.0095,  0.0031, -0.0117,  0.0426,  0.0014, -0.0357, -0.0005, -0.0242,\n",
              "                       0.0198,  0.0228, -0.0198, -0.0318,  0.0019, -0.0179,  0.0042, -0.0179,\n",
              "                       0.0338,  0.0415,  0.0161,  0.0272,  0.0300,  0.0360,  0.0182,  0.0541,\n",
              "                      -0.0006, -0.0445,  0.0245, -0.0445,  0.0534,  0.0106, -0.0393,  0.0021,\n",
              "                      -0.0221, -0.0497, -0.0068,  0.0219, -0.0293, -0.0393,  0.0244,  0.0008,\n",
              "                      -0.0284, -0.0114,  0.0286, -0.0134,  0.0193,  0.0309, -0.0049,  0.0291,\n",
              "                      -0.0073,  0.0316, -0.0429,  0.0222, -0.0207,  0.0303, -0.0229, -0.0332,\n",
              "                      -0.0114,  0.0657,  0.0372,  0.0105,  0.0234, -0.0027,  0.0223,  0.0020,\n",
              "                      -0.0128, -0.0401, -0.0388, -0.0339,  0.0366,  0.0442,  0.0054,  0.0210,\n",
              "                       0.0190, -0.0120,  0.0374, -0.0048,  0.0360,  0.0247, -0.0061, -0.0321,\n",
              "                       0.0163,  0.0079,  0.0164, -0.0167,  0.0306,  0.0192, -0.0377, -0.0213,\n",
              "                      -0.0209,  0.0103, -0.0042,  0.0503, -0.0463, -0.0428,  0.0327,  0.0155,\n",
              "                       0.0493,  0.0018,  0.0129,  0.0391,  0.0332, -0.0215, -0.0127,  0.0019,\n",
              "                      -0.0097, -0.0096,  0.0359, -0.0211, -0.0456,  0.0052,  0.0148, -0.0285,\n",
              "                       0.0015,  0.0258, -0.0362, -0.0158, -0.0128,  0.0736, -0.0423,  0.0385,\n",
              "                      -0.0427, -0.0368,  0.0243, -0.0302, -0.0238, -0.0090, -0.0177,  0.0405,\n",
              "                       0.0193,  0.0539,  0.0004,  0.0070, -0.0192,  0.0519, -0.0019, -0.0058,\n",
              "                       0.0016,  0.0072, -0.0122,  0.0173,  0.0052,  0.0260,  0.0211,  0.0402,\n",
              "                       0.0779, -0.0274, -0.0254,  0.0224, -0.0391, -0.0278,  0.0222, -0.0215,\n",
              "                       0.0188, -0.0133, -0.0154,  0.0059,  0.0653,  0.0005,  0.0507, -0.0328,\n",
              "                       0.0393, -0.0094, -0.0215, -0.0369,  0.0039, -0.0284, -0.0087, -0.0327,\n",
              "                       0.0291,  0.0269, -0.0459, -0.0191,  0.0095,  0.0644, -0.0463,  0.0144,\n",
              "                      -0.0047, -0.0068, -0.0142, -0.0364,  0.0263,  0.0300,  0.0222, -0.0358,\n",
              "                       0.0291, -0.0219, -0.0289, -0.0160,  0.0541,  0.0054,  0.0014, -0.0395,\n",
              "                      -0.0303, -0.0324, -0.0036,  0.0142,  0.0185, -0.0073, -0.0042,  0.0036,\n",
              "                       0.0042, -0.0149, -0.0086,  0.0533,  0.0259,  0.0194, -0.0038, -0.0126,\n",
              "                      -0.0236,  0.0115,  0.0445,  0.0094,  0.0492,  0.0085, -0.0317,  0.0147,\n",
              "                      -0.0421, -0.0327, -0.0415, -0.0012, -0.0319, -0.0029, -0.0141, -0.0234,\n",
              "                       0.0276,  0.0416,  0.0497, -0.0267,  0.0069,  0.0091, -0.0227, -0.0417,\n",
              "                       0.0352, -0.0341, -0.0402,  0.0324, -0.0021,  0.0169,  0.0541,  0.0464,\n",
              "                       0.0028,  0.0176,  0.0514, -0.0017, -0.0228,  0.0288,  0.0223, -0.0004,\n",
              "                       0.0226, -0.0138,  0.0717,  0.0322,  0.0178,  0.0391,  0.0538, -0.0232,\n",
              "                      -0.0448,  0.0311, -0.0155,  0.0159, -0.0216,  0.0377, -0.0117,  0.0118,\n",
              "                      -0.0063,  0.0394, -0.0291, -0.0067, -0.0310,  0.0338, -0.0265,  0.0240,\n",
              "                       0.0502,  0.0125,  0.0419,  0.0184,  0.0172, -0.0163, -0.0091, -0.0368,\n",
              "                      -0.0193, -0.0371,  0.0075,  0.0274,  0.0032,  0.0343,  0.0485,  0.0319,\n",
              "                       0.0025,  0.0100,  0.0741,  0.0286, -0.0086, -0.0514, -0.0393, -0.0279,\n",
              "                       0.0589, -0.0424, -0.0076,  0.0353, -0.0284,  0.0319,  0.0313, -0.0047,\n",
              "                       0.0348, -0.0010,  0.0125,  0.0084,  0.0171, -0.0192, -0.0233, -0.0384,\n",
              "                      -0.0483,  0.0520,  0.0027,  0.0384, -0.0209,  0.0024,  0.0312,  0.0211,\n",
              "                       0.0081,  0.0401,  0.0594, -0.0498, -0.0338, -0.0382,  0.0409,  0.0170,\n",
              "                       0.0686,  0.0349, -0.0270, -0.0247, -0.0213, -0.0045, -0.0255, -0.0018,\n",
              "                      -0.0124,  0.0359, -0.0464,  0.0615,  0.0154, -0.0220, -0.0281,  0.0388,\n",
              "                      -0.0033,  0.0184,  0.0043, -0.0354,  0.0299, -0.0393,  0.0343,  0.0298,\n",
              "                      -0.0327,  0.0361, -0.0274, -0.0490,  0.0060, -0.0073,  0.0064,  0.0363,\n",
              "                      -0.0109, -0.0309,  0.0086, -0.0103,  0.0371, -0.0164,  0.0102,  0.0120,\n",
              "                       0.0406, -0.0163, -0.0029, -0.0378,  0.0417,  0.0158,  0.0171,  0.0020,\n",
              "                       0.0233, -0.0122, -0.0181,  0.0450,  0.0298,  0.0231,  0.0181, -0.0325,\n",
              "                       0.0014,  0.0440,  0.0270, -0.0447,  0.0326,  0.0049, -0.0012,  0.0001,\n",
              "                       0.0636, -0.0112, -0.0215,  0.0250,  0.0155, -0.0201,  0.0380, -0.0129,\n",
              "                       0.0310,  0.0171,  0.0357,  0.0193, -0.0064, -0.0236, -0.0158,  0.0067,\n",
              "                       0.0293,  0.0576, -0.0152,  0.0241,  0.0260,  0.0090,  0.0206, -0.0401,\n",
              "                      -0.0019,  0.0384, -0.0175,  0.0368, -0.0242,  0.0681, -0.0177, -0.0209,\n",
              "                       0.0509,  0.0094, -0.0427, -0.0331,  0.0506,  0.0006,  0.0293, -0.0357,\n",
              "                       0.0205, -0.0092,  0.0471,  0.0279,  0.0071, -0.0167, -0.0291,  0.0202],\n",
              "                     device='cuda:0')),\n",
              "             ('linear_relu_stack.4.weight',\n",
              "              tensor([[ 0.0484,  0.0226,  0.0335,  ..., -0.0003, -0.0314,  0.0054],\n",
              "                      [-0.0475, -0.0141,  0.1000,  ..., -0.0029,  0.0163,  0.0007],\n",
              "                      [ 0.0298, -0.0107, -0.0515,  ..., -0.0370, -0.0074,  0.0419],\n",
              "                      ...,\n",
              "                      [-0.0579,  0.0478, -0.0274,  ..., -0.0125,  0.1316,  0.0234],\n",
              "                      [ 0.0215,  0.0327, -0.0612,  ..., -0.0278, -0.0052, -0.0040],\n",
              "                      [-0.0421,  0.1069, -0.0457,  ...,  0.0291, -0.0061, -0.0099]],\n",
              "                     device='cuda:0')),\n",
              "             ('linear_relu_stack.4.bias',\n",
              "              tensor([-5.6333e-02,  1.5183e-02, -3.3212e-02,  2.2197e-05, -1.0365e-01,\n",
              "                       2.6665e-01, -7.6125e-03,  6.7111e-02, -6.2224e-02, -7.2945e-02],\n",
              "                     device='cuda:0'))])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"my_first_model.pth\"\n",
        "model_pth = \"/content/drive/MyDrive/Cursos/pytorch/models/\" + model_name"
      ],
      "metadata": {
        "id": "joI3Hvx0iYX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), model_pth)\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNpktIDvrUbS",
        "outputId": "25c07ca4-bcd1-4639-a5d4-c31cbb65f37b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork()\n",
        "model.load_state_dict(torch.load(model_pth))\n",
        "print(\"model loaded correctly!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKqzju5wungS",
        "outputId": "64c75e1d-b34d-46eb-f537-8315c1266fe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model loaded correctly!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():\n",
        "  pred = model(x)\n",
        "  predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "  print(f\"Predicted: '{predicted}' Actual: '{actual}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tk98AMYvBaR",
        "outputId": "546511ed-706f-49e7-c218-647c781722c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: 'Ankle boot' Actual: 'Ankle boot'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Using the save model as checkpoint for training step**\n"
      ],
      "metadata": {
        "id": "h0_xhivNykat"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **checkpoint function**\n",
        "We want to save a chekpoint that allows us to use this information to continue our model traning or just for inference. This is the information:\n",
        "* **epoch:** numer of times that our model has seen data for weights update\n",
        "* **valid_loss_min:** the minimum val loss achieved during training phase\n",
        "* **state_dic:** model architecture information\n",
        "* **optimizer:** it computes individual learning rates for different parameters"
      ],
      "metadata": {
        "id": "NikthQn7nYzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaders = {'train': train_dataloader,\n",
        "           'test': test_dataloader}\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "if use_cuda:\n",
        "  model = model.cuda()"
      ],
      "metadata": {
        "id": "hQyJwtwCyOgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_ckp(state, is_best, checkpoint_path, best_model_path):\n",
        "\n",
        "  \"\"\"\n",
        "  state: checkpoint we want to save\n",
        "  is_best: is this the best checkpoint; min validation loss\n",
        "  checkpoint_path: path to save checkpoint\n",
        "  best_model_path: path to save best model\n",
        "  \"\"\"\n",
        "  f_path = checkpoint_path\n",
        "  # save checkpoint data to the path given, checkpoint_path\n",
        "  torch.save(state, f_path)\n",
        "  # if it is a best model, min validation loss\n",
        "  if is_best:\n",
        "    best_fpath = best_model_path\n",
        "    # copy that checkpoint file to best path given, best_model_path\n",
        "    shutil.copyfile(f_path, best_fpath)"
      ],
      "metadata": {
        "id": "eVxnXXEzm7vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Loading function**"
      ],
      "metadata": {
        "id": "oH6A4BwDonNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_ckp(checkpoint_fpath, model, optimizer):\n",
        "  \"\"\"\n",
        "  checkpoint_path: path to save checkpoint\n",
        "  model: model that we want to load checkpoint parameters into       \n",
        "  optimizer: optimizer we defined in previous training\n",
        "  \"\"\"\n",
        "  # load check point\n",
        "  checkpoint = torch.load(checkpoint_fpath)\n",
        "  # initialize state_dict from checkpoint to model\n",
        "  model.load_state_dict(checkpoint['state_dict'])\n",
        "  # initialize optimizer from checkpoint to optimizer\n",
        "  optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "  # initialize valid_loss_min from checkpoint to valid_loss_min\n",
        "  valid_loss_min = checkpoint['valid_loss_min']\n",
        "  # return model, optimizer, epoch value, min validation loss \n",
        "  return model, optimizer, checkpoint['epoch'], valid_loss_min.item()"
      ],
      "metadata": {
        "id": "qrSvl95NopeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Training**"
      ],
      "metadata": {
        "id": "F3jZkVy5q1OE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(start_epochs, n_epochs, valid_loss_min_input, loaders, model, optimizer, criterion, use_cuda,\n",
        "          checkpoint_path, best_model_path):\n",
        "  \"\"\"\n",
        "  Keyword arguments:\n",
        "  start_epochs -- the real part (default 0.0)\n",
        "  n_epochs -- the imaginary part (default 0.0)\n",
        "  valid_loss_min_input\n",
        "  loaders\n",
        "  model\n",
        "  optimizer\n",
        "  criterion\n",
        "  checkpoint_path\n",
        "  best_model_path\n",
        "  \n",
        "  returns trained model\n",
        "  \"\"\"\n",
        "  # initialize tracker for minimum validation loss\n",
        "  valid_loss_min = valid_loss_min_input \n",
        "  \n",
        "  for epoch in range(start_epochs, n_epochs+1):\n",
        "      # initialize variables to monitor training and validation loss\n",
        "      train_loss = 0.0\n",
        "      valid_loss = 0.0\n",
        "      \n",
        "      ###################\n",
        "      # train the model #\n",
        "      ###################\n",
        "      model.train()\n",
        "      for batch_idx, (X, y) in enumerate(loaders['train']):\n",
        "        if use_cuda:\n",
        "          data, target = X.cuda(), y.cuda()\n",
        "\n",
        "        ## find the loss and update the model parameters accordingly\n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "        # perform a single optimization step (parameter update)\n",
        "        optimizer.step()\n",
        "        ## record the average training loss, using something like\n",
        "        ## train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
        "        train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
        "      \n",
        "      ######################    \n",
        "      # validate the model #\n",
        "      ######################\n",
        "      model.eval()\n",
        "      for batch_idx, (X, y) in enumerate(loaders['test']):\n",
        "        if use_cuda:\n",
        "          data, target = X.cuda(), y.cuda()\n",
        "\n",
        "        ## update the average validation loss\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average validation loss \n",
        "        valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
        "          \n",
        "      # calculate average losses\n",
        "      train_loss = train_loss/len(loaders['train'].dataset)\n",
        "      valid_loss = valid_loss/len(loaders['test'].dataset)\n",
        "\n",
        "      # print training/validation statistics \n",
        "      print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "          epoch, \n",
        "          train_loss,\n",
        "          valid_loss\n",
        "          ))\n",
        "      \n",
        "      # create checkpoint variable and add important data\n",
        "      checkpoint = {\n",
        "          'epoch': epoch + 1,\n",
        "          'valid_loss_min': valid_loss,\n",
        "          'state_dict': model.state_dict(),\n",
        "          'optimizer': optimizer.state_dict(),\n",
        "      }\n",
        "      \n",
        "      # save checkpoint\n",
        "      save_ckp(checkpoint, False, checkpoint_path, best_model_path)\n",
        "      \n",
        "      ## TODO: save the model if validation loss has decreased\n",
        "      if valid_loss <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_loss))\n",
        "        # save checkpoint as best model\n",
        "        save_ckp(checkpoint, True, checkpoint_path, best_model_path)\n",
        "        valid_loss_min = valid_loss\n",
        "          \n",
        "  # return trained model\n",
        "  return model"
      ],
      "metadata": {
        "id": "_fkREHyzqqZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"/content/drive/MyDrive/Cursos/pytorch/models/checkpoints/current_checkpoint.pt\"\n",
        "best_model_path = \"/content/drive/MyDrive/Cursos/pytorch/models/best_model/best_model.pt\"\n",
        "\n",
        "trained_model = train(start_epochs=1, n_epochs=5, valid_loss_min_input=np.Inf, loaders=loaders, \n",
        "                      model=model, optimizer=optimizer, criterion=loss_fn, use_cuda=use_cuda, checkpoint_path=checkpoint_path,\n",
        "                      best_model_path=best_model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-3c1gdFqqcd",
        "outputId": "d650ef24-17c5-420b-97d3-71d62457ffd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.000037 \tValidation Loss: 0.000215\n",
            "Validation loss decreased (inf --> 0.000215).  Saving model ...\n",
            "Epoch: 2 \tTraining Loss: 0.000034 \tValidation Loss: 0.000187\n",
            "Validation loss decreased (0.000215 --> 0.000187).  Saving model ...\n",
            "Epoch: 3 \tTraining Loss: 0.000028 \tValidation Loss: 0.000150\n",
            "Validation loss decreased (0.000187 --> 0.000150).  Saving model ...\n",
            "Epoch: 4 \tTraining Loss: 0.000023 \tValidation Loss: 0.000125\n",
            "Validation loss decreased (0.000150 --> 0.000125).  Saving model ...\n",
            "Epoch: 5 \tTraining Loss: 0.000019 \tValidation Loss: 0.000109\n",
            "Validation loss decreased (0.000125 --> 0.000109).  Saving model ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Loading the model**\n",
        "Reconstruct the model"
      ],
      "metadata": {
        "id": "1QX-eTiWwHDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_model = NeuralNetwork()\n",
        "if use_cuda:\n",
        "  model = model.cuda()\n",
        "    \n",
        "print(model)"
      ],
      "metadata": {
        "id": "DvuGOsB_5XKF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e153eff-acd4-4755-f22f-13a2fba3f864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
        "checkpoint_path = \"/content/drive/MyDrive/Cursos/pytorch/models/checkpoints/current_checkpoint.pt\""
      ],
      "metadata": {
        "id": "JV797wEbwXH0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the saved checkpoint\n",
        "model, optimizer, start_epoch, valid_loss_min = load_ckp(checkpoint_path, model, optimizer)"
      ],
      "metadata": {
        "id": "ofecIC1qxCHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Making sure is everything ok\n",
        "print(\"model = \", model)\n",
        "print(\"optimizer = \", optimizer)\n",
        "print(\"start_epoch = \", start_epoch)\n",
        "print(\"valid_loss_min = \", valid_loss_min)\n",
        "print(\"valid_loss_min = {:.6f}\".format(valid_loss_min))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1C1sqP6xJfE",
        "outputId": "44c2d646-6520-4b38-cb1b-6f6cab731e1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model =  NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "optimizer =  SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    foreach: None\n",
            "    lr: 0.001\n",
            "    maximize: False\n",
            "    momentum: 0\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "start_epoch =  6\n",
            "valid_loss_min =  0.0001092103193514049\n",
            "valid_loss_min = 0.000109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Continue training**"
      ],
      "metadata": {
        "id": "fQmbOcmjxi24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = train(start_epoch, n_epochs=10, valid_loss_min_input=valid_loss_min, loaders=loaders, \n",
        "                      model=model, optimizer=optimizer, criterion=loss_fn, use_cuda=use_cuda, checkpoint_path=checkpoint_path,\n",
        "                      best_model_path=best_model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xHtzw8zxSqS",
        "outputId": "ca402f47-3682-461e-91f0-d4761b0d9656"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 6 \tTraining Loss: 0.000017 \tValidation Loss: 0.000099\n",
            "Validation loss decreased (0.000109 --> 0.000099).  Saving model ...\n",
            "Epoch: 7 \tTraining Loss: 0.000016 \tValidation Loss: 0.000092\n",
            "Validation loss decreased (0.000099 --> 0.000092).  Saving model ...\n",
            "Epoch: 8 \tTraining Loss: 0.000015 \tValidation Loss: 0.000087\n",
            "Validation loss decreased (0.000092 --> 0.000087).  Saving model ...\n",
            "Epoch: 9 \tTraining Loss: 0.000014 \tValidation Loss: 0.000083\n",
            "Validation loss decreased (0.000087 --> 0.000083).  Saving model ...\n",
            "Epoch: 10 \tTraining Loss: 0.000013 \tValidation Loss: 0.000079\n",
            "Validation loss decreased (0.000083 --> 0.000079).  Saving model ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ko3SgflqyBCd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}